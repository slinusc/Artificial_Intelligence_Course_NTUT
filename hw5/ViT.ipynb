{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyMZNLviD4r/GOt/eeoIcZYK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3GbcOgp9Pvcm","outputId":"a432d20a-5c8a-40dc-87b0-b4c96e34147c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","<ipython-input-1-ca22a4771f76>:46: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = GradScaler()\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining:   0%|          | 0/196 [00:00<?, ?it/s]<ipython-input-1-ca22a4771f76>:64: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast():  # Mixed precision\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.7920, Test Loss: 0.6540, Accuracy: 93.59%\n","Epoch 2/20\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.6154, Test Loss: 0.6126, Accuracy: 95.21%\n","Epoch 3/20\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.5860, Test Loss: 0.6115, Accuracy: 95.23%\n","Epoch 4/20\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.5635, Test Loss: 0.5978, Accuracy: 95.96%\n","Epoch 5/20\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.5467, Test Loss: 0.6055, Accuracy: 95.46%\n","Epoch 6/20\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating:  68%|██████▊   | 27/40 [00:23<00:11,  1.18it/s]"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torchvision.models import vit_b_16\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from torch.cuda.amp import GradScaler, autocast\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","\n","# 1. Device Configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# 2. Data Preparation with Augmentation\n","transform_train = transforms.Compose([\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.Resize((224, 224)),  # Resize for ViT input\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.Resize((224, 224)),  # Resize for ViT input\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n","test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=256, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=False)\n","\n","# 3. Model Setup with Pretrained Weights\n","model = vit_b_16(pretrained=True)\n","model.heads.head = nn.Linear(model.heads.head.in_features, 10)  # Update classifier for CIFAR-10\n","model = model.to(device)\n","\n","# 4. Loss, Optimizer, and Scheduler\n","criterion = nn.CrossEntropyLoss(label_smoothing=0.1)  # Label smoothing\n","optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n","scheduler = CosineAnnealingLR(optimizer, T_max=10)  # Learning rate scheduler\n","\n","# 5. Mixed Precision Training Setup\n","scaler = GradScaler()\n","\n","# 6. Training and Evaluation\n","num_epochs = 20\n","train_losses = []\n","test_losses = []\n","accuracy = []\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    print(f\"Epoch {epoch+1}/{num_epochs}\")\n","\n","    # Training loop\n","    for images, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        with autocast():  # Mixed precision\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","        scaler.scale(loss).backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        running_loss += loss.item()\n","\n","    train_losses.append(running_loss / len(train_loader))\n","\n","    # Evaluation loop\n","    model.eval()\n","    test_loss = 0.0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for images, labels in tqdm(test_loader, desc=\"Evaluating\", leave=False):\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            test_loss += loss.item()\n","\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    test_losses.append(test_loss / len(test_loader))\n","    accuracy.append(100 * correct / total)\n","    scheduler.step()  # Adjust learning rate\n","\n","    print(f\"Train Loss: {train_losses[-1]:.4f}, Test Loss: {test_losses[-1]:.4f}, Accuracy: {accuracy[-1]:.2f}%\")\n","\n","# 7. Visualization\n","plt.figure(figsize=(12, 4))\n","plt.subplot(1, 2, 1)\n","plt.plot(train_losses, label='Train Loss')\n","plt.plot(test_losses, label='Test Loss')\n","plt.title('Loss Curves')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(accuracy, label='Accuracy')\n","plt.title('Accuracy Curve')\n","plt.legend()\n","plt.show()\n","\n","# 8. Save Misclassified Examples\n","misclassified = []\n","model.eval()\n","with torch.no_grad():\n","    for images, labels in tqdm(test_loader, desc=\"Finding Misclassified\", leave=False):\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs, 1)\n","        for i in range(len(labels)):\n","            if predicted[i] != labels[i]:\n","                misclassified.append((images[i].cpu(), labels[i].cpu(), predicted[i].cpu()))\n","\n","# Visualize 5 misclassified images\n","plt.figure(figsize=(10, 5))\n","for i in range(min(5, len(misclassified))):\n","    img, true_label, pred_label = misclassified[i]\n","    img = img.permute(1, 2, 0) * 0.5 + 0.5  # De-normalize\n","    plt.subplot(1, 5, i+1)\n","    plt.imshow(img)\n","    plt.title(f\"True: {true_label}, Pred: {pred_label}\")\n","    plt.axis('off')\n","plt.show()\n"]}]}