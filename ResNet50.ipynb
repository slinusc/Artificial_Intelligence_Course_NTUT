{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","mount_file_id":"1t4AfRAtrcZCYkPgmvZGqtalrNYpumWww","authorship_tag":"ABX9TyPoS1i/39hSWvsS2bYh1HPE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import os\n","import pickle\n","import numpy as np\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from tqdm import tqdm"],"metadata":{"id":"sU_iced07TO3","executionInfo":{"status":"ok","timestamp":1729159524181,"user_tz":-480,"elapsed":3251,"user":{"displayName":"Linus Stuhlmann","userId":"07279173608860907824"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# Custom Dataset class for CIFAR-10 with lazy loading\n","class CIFAR10Dataset(Dataset):\n","    def __init__(self, data_path, batch_files, transform=None):\n","        self.data_path = data_path\n","        self.batch_files = batch_files\n","        self.transform = transform\n","        self.batch_data = None  # Only load the necessary batch when needed\n","        self.batch_labels = None\n","        self.batch_index = -1  # Track the currently loaded batch\n","        self.index_map = []  # Maps dataset index to batch index and in-batch index\n","        self._create_index_map()\n","\n","    def _create_index_map(self):\n","        \"\"\"Create a map of global indices to batch indices.\"\"\"\n","        start_idx = 0\n","        for batch_num, batch_file in enumerate(self.batch_files):\n","            with open(os.path.join(self.data_path, batch_file), 'rb') as f:\n","                batch = pickle.load(f, encoding='bytes')\n","                batch_size = len(batch[b'labels'])\n","                self.index_map.extend([(batch_num, i) for i in range(batch_size)])\n","            start_idx += batch_size\n","\n","    def _load_batch(self, batch_num):\n","        \"\"\"Load a batch given its batch number.\"\"\"\n","        batch_file = self.batch_files[batch_num]\n","        with open(os.path.join(self.data_path, batch_file), 'rb') as f:\n","            batch = pickle.load(f, encoding='bytes')\n","            self.batch_data = batch[b'data'].reshape(-1, 3, 32, 32)\n","            self.batch_labels = batch[b'labels']\n","        self.batch_index = batch_num  # Update currently loaded batch\n","\n","    def __len__(self):\n","        return len(self.index_map)\n","\n","    def __getitem__(self, idx):\n","        # Map global index to batch number and in-batch index\n","        batch_num, in_batch_idx = self.index_map[idx]\n","\n","        # Load the batch if it's not already loaded\n","        if batch_num != self.batch_index:\n","            self._load_batch(batch_num)\n","\n","        # Fetch image and label from the loaded batch\n","        image = self.batch_data[in_batch_idx]\n","        label = self.batch_labels[in_batch_idx]\n","\n","        # Convert to the expected format (H x W x C)\n","        image = image.transpose(1, 2, 0)\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, label\n","\n","\n","# Transformations for CIFAR-10 (ResNet expects 224x224 images)\n","transform = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.Resize((224, 224)),  # ResNet-50 requires 224x224 input size\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize the images\n","])"],"metadata":{"id":"pJ0Qddj67W7h","executionInfo":{"status":"ok","timestamp":1729159524181,"user_tz":-480,"elapsed":8,"user":{"displayName":"Linus Stuhlmann","userId":"07279173608860907824"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Path to the dataset in your Google Drive\n","data_path = '/content/drive/MyDrive/Artificial_Intelligence_Course_NTUT/cifar-10-python/cifar-10-batches-py/'\n","\n","# Training and test batch file names\n","train_batches = [f'data_batch_{i}' for i in range(1, 6)]\n","test_batches = ['test_batch']\n","\n","# Create Dataset instances\n","train_dataset = CIFAR10Dataset(data_path, train_batches, transform=transform)\n","test_dataset = CIFAR10Dataset(data_path, test_batches, transform=transform)\n","\n","# Create DataLoader for train and test datasets\n","trainloader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=4)\n","testloader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=4)\n","\n","# Model, Loss, and Optimizer setup\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision.models import resnet50\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = resnet50(pretrained=True)\n","\n","# Modify the fully connected layer to match CIFAR-10 (10 classes)\n","num_ftrs = model.fc.in_features\n","model.fc = nn.Linear(num_ftrs, 10)\n","model = model.to(device)\n","\n","# Loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cBFnXIqO7acL","executionInfo":{"status":"ok","timestamp":1729159525177,"user_tz":-480,"elapsed":1003,"user":{"displayName":"Linus Stuhlmann","userId":"07279173608860907824"}},"outputId":"f6ac9660-0472-4730-e019-c3ff6dbdc336"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}]},{"cell_type":"code","source":["# Training loop with progress bar\n","def train_model(model, trainloader, criterion, optimizer, num_epochs=10):\n","    model.train()\n","\n","    for epoch in range(num_epochs):\n","        running_loss = 0.0\n","        correct = 0\n","        total = 0\n","\n","        # Create a progress bar for each epoch\n","        progress_bar = tqdm(enumerate(trainloader), total=len(trainloader), desc=f'Epoch {epoch+1}/{num_epochs}')\n","\n","        for i, (inputs, labels) in progress_bar:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()  # Zero the gradients\n","\n","            # Forward pass\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","\n","            # Backward pass and optimization\n","            loss.backward()\n","            optimizer.step()\n","\n","            # Accumulate statistics\n","            running_loss += loss.item() * inputs.size(0)\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","            # Update the progress bar with loss and accuracy information\n","            progress_bar.set_postfix(loss=loss.item(), accuracy=correct / total * 100)\n","\n","        # Calculate epoch statistics\n","        epoch_loss = running_loss / len(trainloader.dataset)\n","        epoch_acc = correct / total * 100\n","        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')\n","\n","    print('Finished Training')\n","\n","\n","# Training the model\n","train_model(model, trainloader, criterion, optimizer, num_epochs=10)\n","\n","# Testing loop (optional)\n","def test_model(model, testloader):\n","    model.eval()  # Set model to evaluation mode\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for inputs, labels in testloader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    print(f'Test Accuracy: {correct / total * 100:.2f}%')\n","\n","# Test the model\n","test_model(model, testloader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RjPLcDfY5uPD","outputId":"9f6b519d-0212-4281-b769-c0f7684dba3c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1/10:  67%|██████▋   | 132/196 [07:59<02:49,  2.64s/it, accuracy=80.1, loss=0.409]"]}]}]}