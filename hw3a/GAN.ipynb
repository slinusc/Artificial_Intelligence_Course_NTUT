{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19310,"status":"ok","timestamp":1736180474972,"user":{"displayName":"Linus Stuhlmann","userId":"07279173608860907824"},"user_tz":-480},"id":"eNA59NAbUomN","outputId":"cffc3e86-3429-46d7-fd75-6443b5c717f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BHUa997C-54R","outputId":"0afdeb20-cc87-4cb7-ab70-ea6baa8ec229"},"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1/200: 100%|██████████| 297/297 [00:14<00:00, 21.09batch/s, Loss D=0.135, Loss G=6.31]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/200] Loss D: 0.1353, Loss G: 6.3112\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/200: 100%|██████████| 297/297 [00:13<00:00, 21.46batch/s, Loss D=0.067, Loss G=0.779]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [2/200] Loss D: 0.0670, Loss G: 0.7789\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/200: 100%|██████████| 297/297 [00:14<00:00, 21.21batch/s, Loss D=0.113, Loss G=0.862]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [3/200] Loss D: 0.1126, Loss G: 0.8616\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/200: 100%|██████████| 297/297 [00:13<00:00, 21.31batch/s, Loss D=0.713, Loss G=3.83]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [4/200] Loss D: 0.7134, Loss G: 3.8333\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/200: 100%|██████████| 297/297 [00:13<00:00, 21.50batch/s, Loss D=0.0909, Loss G=0.716]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [5/200] Loss D: 0.0909, Loss G: 0.7156\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6/200: 100%|██████████| 297/297 [00:13<00:00, 21.46batch/s, Loss D=0.104, Loss G=0.607]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [6/200] Loss D: 0.1039, Loss G: 0.6067\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7/200: 100%|██████████| 297/297 [00:13<00:00, 21.38batch/s, Loss D=0.0433, Loss G=0.671]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [7/200] Loss D: 0.0433, Loss G: 0.6708\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8/200: 100%|██████████| 297/297 [00:13<00:00, 21.47batch/s, Loss D=0.0776, Loss G=0.937]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [8/200] Loss D: 0.0776, Loss G: 0.9368\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9/200: 100%|██████████| 297/297 [00:14<00:00, 21.19batch/s, Loss D=0.0633, Loss G=0.792]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [9/200] Loss D: 0.0633, Loss G: 0.7921\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10/200: 100%|██████████| 297/297 [00:13<00:00, 21.26batch/s, Loss D=0.0801, Loss G=0.718]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [10/200] Loss D: 0.0801, Loss G: 0.7177\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 11/200: 100%|██████████| 297/297 [00:13<00:00, 21.32batch/s, Loss D=0.0137, Loss G=0.985]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [11/200] Loss D: 0.0137, Loss G: 0.9850\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 12/200: 100%|██████████| 297/297 [00:13<00:00, 21.24batch/s, Loss D=0.0216, Loss G=0.845]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [12/200] Loss D: 0.0216, Loss G: 0.8447\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 13/200: 100%|██████████| 297/297 [00:13<00:00, 21.32batch/s, Loss D=0.00718, Loss G=0.894]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [13/200] Loss D: 0.0072, Loss G: 0.8941\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 14/200: 100%|██████████| 297/297 [00:13<00:00, 21.54batch/s, Loss D=1.14, Loss G=0.0737]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [14/200] Loss D: 1.1403, Loss G: 0.0737\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 15/200: 100%|██████████| 297/297 [00:13<00:00, 21.42batch/s, Loss D=0.0748, Loss G=0.487]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [15/200] Loss D: 0.0748, Loss G: 0.4869\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 16/200: 100%|██████████| 297/297 [00:14<00:00, 21.20batch/s, Loss D=0.0132, Loss G=0.74]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [16/200] Loss D: 0.0132, Loss G: 0.7404\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 17/200: 100%|██████████| 297/297 [00:13<00:00, 21.35batch/s, Loss D=0.00997, Loss G=0.971]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [17/200] Loss D: 0.0100, Loss G: 0.9708\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 18/200: 100%|██████████| 297/297 [00:13<00:00, 21.26batch/s, Loss D=0.00657, Loss G=1.02]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [18/200] Loss D: 0.0066, Loss G: 1.0183\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 19/200: 100%|██████████| 297/297 [00:13<00:00, 21.24batch/s, Loss D=0.0553, Loss G=0.647]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [19/200] Loss D: 0.0553, Loss G: 0.6471\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 20/200: 100%|██████████| 297/297 [00:13<00:00, 21.26batch/s, Loss D=0.0212, Loss G=0.72]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [20/200] Loss D: 0.0212, Loss G: 0.7197\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 21/200: 100%|██████████| 297/297 [00:13<00:00, 21.39batch/s, Loss D=0.00849, Loss G=0.917]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [21/200] Loss D: 0.0085, Loss G: 0.9174\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 22/200: 100%|██████████| 297/297 [00:13<00:00, 21.34batch/s, Loss D=0.0233, Loss G=1.36]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [22/200] Loss D: 0.0233, Loss G: 1.3552\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 23/200: 100%|██████████| 297/297 [00:13<00:00, 21.34batch/s, Loss D=0.0341, Loss G=0.635]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [23/200] Loss D: 0.0341, Loss G: 0.6350\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 24/200: 100%|██████████| 297/297 [00:13<00:00, 21.48batch/s, Loss D=0.00515, Loss G=0.893]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [24/200] Loss D: 0.0051, Loss G: 0.8931\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 25/200: 100%|██████████| 297/297 [00:13<00:00, 21.31batch/s, Loss D=0.00279, Loss G=0.98]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [25/200] Loss D: 0.0028, Loss G: 0.9798\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 26/200:  99%|█████████▉| 294/297 [00:13<00:00, 21.66batch/s, Loss D=0.026, Loss G=1.36]"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision.utils import save_image\n","from torch.utils.data import DataLoader, Dataset\n","from torchvision import transforms\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","from tqdm import tqdm\n","\n","# ----------------\n","#   Generator\n","# ----------------\n","class Generator(nn.Module):\n","    def __init__(self, ngpu, nc=1, nz=100, ngf=64):\n","        super(Generator, self).__init__()\n","        self.ngpu = ngpu\n","        self.main = nn.Sequential(\n","            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n","            nn.BatchNorm2d(ngf * 8),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf * 4),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf * 2),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n","            nn.Tanh()\n","        )\n","\n","    def forward(self, input):\n","        return self.main(input)\n","\n","# ----------------\n","#   Discriminator\n","# ----------------\n","class Discriminator(nn.Module):\n","    def __init__(self, ngpu, nc=1, ndf=64):\n","        super(Discriminator, self).__init__()\n","        self.ngpu = ngpu\n","        self.main = nn.Sequential(\n","            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 4),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 8),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n","        )\n","\n","    def forward(self, x):\n","        return self.main(x).view(-1)\n","\n","# ----------------\n","#   Dataset Loader\n","# ----------------\n","class WaferMapDataset(Dataset):\n","    def __init__(self, file_path, transform=None):\n","        with np.load(file_path) as data:\n","            self.data = data['arr_0']\n","            self.onehot_labels = data['arr_1']\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        img = self.data[idx].astype(np.float32)\n","        if self.transform:\n","            img = self.transform(img)\n","        return img\n","\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Resize((64, 64)),\n","    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize to [-1, 1]\n","])\n","\n","dataset = WaferMapDataset(\n","    file_path=\"/content/drive/MyDrive/Artificial_Intelligence_Course_NTUT/hw3a/Wafer_Map_Datasets.npz\",\n","    transform=transform\n",")\n","loader = DataLoader(dataset, batch_size=128, shuffle=True)\n","\n","# ----------------\n","#   Weight Initialization\n","# ----------------\n","def weights_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find(\"Conv\") != -1:\n","        nn.init.normal_(m.weight.data, 0.0, 0.02)\n","    elif classname.find(\"BatchNorm\") != -1:\n","        nn.init.normal_(m.weight.data, 1.0, 0.02)\n","        nn.init.constant_(m.bias.data, 0)\n","\n","# ----------------\n","#   Initialize\n","# ----------------\n","generator = Generator(ngpu=1, nc=1, nz=100, ngf=64).to(\"cuda\")\n","discriminator = Discriminator(ngpu=1, nc=1, ndf=64).to(\"cuda\")\n","\n","generator.apply(weights_init)\n","discriminator.apply(weights_init)\n","\n","criterion = nn.MSELoss()\n","optim_gen = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","optim_disc = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","\n","# -----------------------------\n","#   Simple Visualization\n","# -----------------------------\n","def visualize_real_and_generated(dataset, generator, epoch, save_path=\"./\"):\n","    rows, cols = 2, 8\n","    fig, axs = plt.subplots(rows, cols, figsize=(cols*2.0, rows*2.0))\n","    axs = axs.flatten()\n","\n","    for i in range(cols):\n","        real_img = dataset[i]\n","        axs[i].imshow(real_img.squeeze(), cmap=\"gray\")\n","        axs[i].set_title(\"Real\")\n","        axs[i].axis(\"off\")\n","\n","    noise = torch.randn(cols, 100, 1, 1).to(\"cuda\")\n","    with torch.no_grad():\n","        fake_imgs = generator(noise).cpu()\n","    for i in range(cols):\n","        axs[cols + i].imshow(fake_imgs[i].squeeze(), cmap=\"gray\")\n","        axs[cols + i].set_title(\"Fake\")\n","        axs[cols + i].axis(\"off\")\n","\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(save_path, f\"epoch_{epoch}_visualization    .png\"))\n","    plt.close()\n","\n","# ----------------\n","#   Training Loop\n","# ----------------\n","losses_gen = []\n","losses_disc = []\n","\n","for epoch in range(200):\n","    pbar = tqdm(loader, desc=f\"Epoch {epoch + 1}/200\", unit=\"batch\")\n","    for real in pbar:\n","        real = real.view(real.size(0), 1, 64, 64).to(\"cuda\")\n","        batch_size = real.size(0)\n","\n","        # Train Discriminator\n","        noise = torch.randn(batch_size, 100, 1, 1).to(\"cuda\")\n","        fake = generator(noise)\n","\n","        real_labels = torch.ones(batch_size, device=real.device)\n","        fake_labels = torch.zeros(batch_size, device=real.device)\n","\n","        disc_real = discriminator(real).view(-1)\n","        disc_fake = discriminator(fake.detach()).view(-1)\n","\n","        loss_disc_real = criterion(disc_real, real_labels)\n","        loss_disc_fake = criterion(disc_fake, fake_labels)\n","        loss_disc = (loss_disc_real + loss_disc_fake) / 2\n","\n","        optim_disc.zero_grad()\n","        loss_disc.backward()\n","        optim_disc.step()\n","\n","        # Train Generator\n","        fake = generator(noise)\n","        disc_fake = discriminator(fake).view(-1)\n","        loss_gen = criterion(disc_fake, real_labels)\n","\n","        optim_gen.zero_grad()\n","        loss_gen.backward()\n","        optim_gen.step()\n","\n","        pbar.set_postfix({\"Loss D\": loss_disc.item(), \"Loss G\": loss_gen.item()})\n","\n","    losses_gen.append(loss_gen.item())\n","    losses_disc.append(loss_disc.item())\n","\n","    print(f\"Epoch [{epoch + 1}/200] Loss D: {loss_disc:.4f}, Loss G: {loss_gen:.4f}\")\n","\n","    # Visualization\n","    if (epoch + 1) % 10 == 0:\n","        visualize_real_and_generated(dataset, generator, epoch + 1, save_path=\"/content/drive/MyDrive/Artificial_Intelligence_Course_NTUT/hw3a/output\")\n","\n","# Save final models\n","torch.save(generator.state_dict(), \"/content/drive/MyDrive/Artificial_Intelligence_Course_NTUT/hw3a/models/optimized_generator.pth\")\n","torch.save(discriminator.state_dict(), \"/content/drive/MyDrive/Artificial_Intelligence_Course_NTUT/hw3a/models/optimized_discriminator.pth\")"]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","def plot_loss_curves(losses_gen, losses_disc, save_path=None):\n","    \"\"\"\n","    Plot the generator and discriminator loss curves.\n","\n","    Args:\n","        losses_gen (list): Generator losses per epoch.\n","        losses_disc (list): Discriminator losses per epoch.\n","        save_path (str, optional): Path to save the plot. Defaults to None.\n","    \"\"\"\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(losses_gen, label=\"Generator Loss\", linewidth=2)\n","    plt.plot(losses_disc, label=\"Discriminator Loss\", linewidth=2)\n","    plt.title(\"Loss Curves\", fontsize=16)\n","    plt.xlabel(\"Epoch\", fontsize=14)\n","    plt.ylabel(\"Loss\", fontsize=14)\n","    plt.legend(fontsize=12)\n","    plt.grid(True)\n","\n","    # Save or show the plot\n","    if save_path:\n","        plt.savefig(save_path)\n","        print(f\"Loss curves saved to {save_path}\")\n","    else:\n","        plt.show()\n","\n","# Call the function after training\n","plot_loss_curves(\n","    losses_gen=losses_gen,\n","    losses_disc=losses_disc,\n","    save_path=\"/content/drive/MyDrive/Artificial_Intelligence_Course_NTUT/hw3a/output/loss_curves.png\"\n",")\n"],"metadata":{"id":"qPC9fXQoh93t"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}